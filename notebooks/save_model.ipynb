{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pickling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# Function to save a single dataframe using Pickle\n",
    "def save_dataframe(dataframe, filename):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    - dataframe: The pandas DataFrame to save.\n",
    "    - filename: The file path (including name) where the DataFrame will be stored.\n",
    "    \"\"\"\n",
    "    with open(filename, 'wb') as file:\n",
    "        pickle.dump(dataframe, file)  # Serialize \n",
    "        print(f\"DataFrame saved to {filename}\")\n",
    "\n",
    "# Function to save multiple dataframes iteratively\n",
    "def save_multiple_dataframes(dataframes, save_directory):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    - dataframes: A list of pandas DataFrames to save.\n",
    "    - save_directory: Directory path to store the pickle files.\n",
    "    \"\"\"\n",
    "    # Ensure the directory exists\n",
    "    if not os.path.exists(save_directory):\n",
    "        os.makedirs(save_directory)\n",
    "    \n",
    "    # Iterate through the list of DataFrames\n",
    "    for i, df in enumerate(dataframes):\n",
    "        filename = os.path.join(save_directory, f\"dataframe_{i + 1}.pkl\")\n",
    "        save_dataframe(df, filename)\n",
    "\n",
    "# Function to load a single dataframe from a pickle file\n",
    "def load_dataframe(filename):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    - filename: The file path (including name) to load the DataFrame from.\n",
    "    Returns:\n",
    "    - dataframe: The pandas DataFrame loaded from the pickle file.\n",
    "    \"\"\"\n",
    "    with open(filename, 'rb') as file:\n",
    "        dataframe = pickle.load(file)  # Deserialize the DataFrame from the pickle file\n",
    "        print(f\"DataFrame loaded from {filename}\")\n",
    "        return dataframe\n",
    "\n",
    "# Function to load multiple dataframes from pickle files in a directory\n",
    "def load_multiple_dataframes(save_directory):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    - save_directory: Directory path where pickle files are stored.\n",
    "    Returns:\n",
    "    - dataframes: A list of pandas DataFrames loaded from the pickle files.\n",
    "    \"\"\"\n",
    "    dataframes = []\n",
    "    pickle_files = [f for f in os.listdir(save_directory) if f.endswith('.pkl')]  # List of pickle files\n",
    "    \n",
    "    # Iterate over all pickle files and load them\n",
    "    for pickle_file in pickle_files:\n",
    "        file_path = os.path.join(save_directory, pickle_file)\n",
    "        df = load_dataframe(file_path)\n",
    "        dataframes.append(df)\n",
    "    \n",
    "    return dataframes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final version\n",
    "\n",
    "import telemetry_parser\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from config import config\n",
    "from pprint import pprint\n",
    "from pathlib import Path\n",
    "\n",
    "def extract_imu_data(file: Path):\n",
    "    tp = telemetry_parser.Parser(str(file))\n",
    "    # Define the columns for the dataframe\n",
    "    kolommen = ['TIMESTAMP', 'ACCL_x', 'ACCL_y', 'ACCL_z', 'GYRO_x', 'GYRO_y', 'GYRO_z']\n",
    "    imu_data_df = pd.DataFrame(columns=kolommen)\n",
    "\n",
    "    # Retrieve the length of the data, assuming tp.normalized_imu() returns a list of IMU data samples\n",
    "    imu_data = tp.normalized_imu()  # Data retrieved from normalized_imu function\n",
    "    length = len(imu_data)  # Get the number of IMU data samples\n",
    "    # print(length)\n",
    "\n",
    "    all_rows = []\n",
    "\n",
    "    # Iterate over each telemetry sample (second)\n",
    "    for i in range(length):\n",
    "        timestamp_s = imu_data[i]['timestamp_ms'] / 1000  # Convert from ms to seconds\n",
    "        \n",
    "        # Retrieve accelerometer and gyroscope data for the current sample\n",
    "        accl_data = imu_data[i]['accl']\n",
    "        gyro_data = imu_data[i]['gyro']\n",
    "        \n",
    "        # Extract x, y, z components from the accelerometer and gyroscope data\n",
    "        accl_x, accl_y, accl_z = accl_data\n",
    "        gyro_x, gyro_y, gyro_z = gyro_data\n",
    "        \n",
    "        # Create a new row with the timestamp and sensor data\n",
    "        new_row = [timestamp_s, accl_x, accl_y, accl_z, gyro_x, gyro_y, gyro_z]\n",
    "        all_rows.append(new_row)\n",
    "\n",
    "    imu_data_df = pd.DataFrame(all_rows, columns=kolommen)\n",
    "\n",
    "    # Optionally save the DataFrame to a CSV file\n",
    "    imu_data_df.to_csv(config.DATA_DIR / 'normalized_imu_data.csv', index=False)\n",
    "    \n",
    "    return imu_data_df\n",
    "\n",
    "\n",
    "x = (extract_imu_data('data/raf_frames.MP4'))\n",
    "display(x.head(100))\n",
    "display(x.tail(100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = extract_imu_data('data/raf_frames.MP4')\n",
    "df2 = extract_imu_data('data/GH010045.MP4')\n",
    "directory = 'pickled_bytestream'\n",
    "\n",
    "dataframes = [df1, df2]\n",
    "\n",
    "# Check if the directory exists, if not create it\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "\n",
    "# Now, save the DataFrame to a pickle file inside the directory\n",
    "filename = os.path.join(directory, 'imu_data.pkl')  # Specify the file name with .pkl extension\n",
    "\n",
    "save_dataframe(df1, filename)\n",
    "\n",
    "save_multiple_dataframes(dataframes, directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load_dataframe('pickled_bytestream/imu_data.pkl')\n",
    "\n",
    "load_multiple_dataframes('pickled_bytestream')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
